---
title: "Hoeffding Intervals"
author: "Matthew Edwards"
date: "11/05/2021"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction

Confidence intervals on metrics are great for understanding how well you have estimated the performance of a model and for understanding if one model is better than another. 

For classification models there is one confidence interval that can be used for 

- accuracy
- precision
- recall
- sensitivity
- specificity 

that has the advantage of being **exact** an **non-parmetric**. This is the Hoeffding Confidence Interval (HCI).

## Set up

For now assume that there are $n$ Bernoulli random variables $X_i\sim\text{Bern}(p)$ with expectation $p$ and the average $\overline{X}_n$ is used as an estimate of $p$. 

We would like to be **confident** ($\delta$) that the difference between the expectation and the average (i.e. $\vert\overline{X}_n-p\vert$) is within some **error** ($\epsilon$):

$$
P(\vert\overline{X}_n-p\vert\leq\epsilon)\geq\delta
$$

The $\delta$% CI is $[\max\{\overline{X}_n-\epsilon, 0\}, \min\{\overline{X}_n+\epsilon, 1\}]$.

## Hoeffding 1

Hoeffding takes

$$
P(\vert\overline{X}_n-p\vert\leq\epsilon)\geq\delta
$$

and provides a relationship between $\epsilon$, $\delta$ and $n$:

$$
\epsilon=\sqrt{\frac{\ln(2)-\ln(1-\delta)}{2n}}
$$

so if you want a 95\% HCI (i.e. $\delta=0.95$) with data size $n=100$ you can calculate $\epsilon$ and construct the interval in the previous slide.

## Hoeffding 2

You can even rearrange the relationship:

$$
n=\frac{\ln(2)-\ln(1-\delta)}{2\epsilon^2}
$$

so if you want a 95\% HCI (i.e. $\delta=0.95$) with error $\epsilon=0.01$ you can calculate $n$ to know how much data you will need.

## Application to Metrics

For different metrics $n$ has different values:

- **Accuracy**: number of examples
- **Precision**: number of examples classified as positive
- **Recall**: number of examples that are positive
- **Sensitivity**: number of examples that are positive
- **Specificity**: number of examples that are negative

## Code

This can all be done with a very simple python function:

```
def hoeffding_interval(n, delta, estimate):
    epsilon = math.sqrt((math.log(2)-math.log(1-delta))/(2*n))
    return (max(estimate-epsilon,0),min(estimate+epsilon,1))
```

For example if my estimate $\overline{X}_n=0.8$ then:

```
>>> import math
>>> hoeffding_interval(100, 0.95, 0.8)
(0.6641898484259381, 0.935810151574062)
```