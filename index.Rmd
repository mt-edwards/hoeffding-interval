---
title: "Hoeffding Intervals"
author: "Matthew Edwards"
date: "11/05/2021"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction

Confidence intervals on metrics are great for understanding how well you have estimated the performance of a model and for understanding if one model is better than another. 

For classification models there is one confidence interval that can be used for 

- accuracy
- precision
- recall
- sensitivity
- specificity 

that has the advantage of being **exact** and **non-parametric**. This is the Hoeffding Confidence Interval.

## Set up

For now assume that there are $n$ binary random variables $X_i\in\{0,1\}$ with expectation $p$ and the average of these binary random variables, denoted $\hat{p}_n$, is used to estimate $p$.

**Accuracy**

For the accuracy metric the binary random variable $X_i$ indicates if the $i$th example is correctly classified ($X_i=0$) or incorrectly classified ($X_i=1$). $\hat{p}_n$ is the proportion of correctly classified examples on the test set and $p$ is the accuracy of the classifier.

## Hoeffding Confidence Interval

Hoeffding proved that

$$
\hat{p}_n\pm\epsilon
$$

is a $(1-\delta)$% confidence interval with sample size $n$ if

$$
\epsilon=\sqrt{\frac{\ln(2/\delta)}{2n}}.
$$

For example, a 95% confidence interval (i.e. $\delta=0.05$) with a sample size of $n=1000$ has an error of approximately 4.29% with confidence interval $\hat{p}_{1000}\pm0.0429$

## Bound Issues

With small $n$ sometimes $\hat{p}_n-\epsilon<0$ or $\hat{p}_n+\epsilon>1$. In this case we can redefine the upper and lower bounds as

$$
[\max\{\hat{p}_n-\epsilon, 0\}, \min\{\hat{p}_n+\epsilon, 1\}]
$$
and this remains a $(1-\delta)$% confidence interval.

## Power Calculation

Hoeffding also proved that 

$$
\hat{p}_n\pm\epsilon
$$

is a $(1-\delta)$% confidence interval with error $\epsilon$ if 

$$
n\geq\frac{\ln(2/\delta)}{2\epsilon^2}.
$$

**This can be used to calculate the test set size.**

## Application to Metrics

For different metrics $n$ has different values:

- **Accuracy**: number of examples
- **Precision**: number of examples classified as positive
- **Recall**: number of examples that are positive
- **Sensitivity**: number of examples that are positive
- **Specificity**: number of examples that are negative

## Code

This can all be done with a very simple python function:

```
def hoeffding_interval(n, delta, estimate):
    epsilon = math.sqrt((math.log(2/delta))/(2*n))
    return (max(estimate-epsilon,0),min(estimate+epsilon,1))
```

For example if my estimate $\hat{p}_n=0.8$ then:

```
>>> import math
>>> hoeffding_interval(100, 0.05, 0.8)
(0.6641898484259381, 0.935810151574062)
```